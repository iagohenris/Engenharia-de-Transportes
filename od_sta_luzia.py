# -*- coding: utf-8 -*-
"""OD_PTT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N-wXvTx4tiqzePReQYMbdaRTbr2NJ00H

---
"""
#%%
#**ÍNICIO**
#**PREPARANDO DADOS**
#importando bibliotecas
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import geopandas as gpd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import os
import statsmodels.api as sm
#para não dar pau no caminho do arquivo eu uso esse campo do OS - funções do sistema
ROOT = os.path.dirname(__file__)

#%%
#lendo os arquivos em excel com os dados da OD
dom = pd.read_excel(ROOT+'/Od_Domic_2012.xlsx')
ind = pd.read_excel(ROOT+'/OD_Individuos_2012.xlsx')
via = pd.read_excel(ROOT+'/OD_Viagens_2012.xlsx')
#%%
#OD INDIVIDUOS
#agrupando dados de faixa etária
ind['range_idade']= pd.cut(ind.idade,bins=range(0,112,5),include_lowest=True)
#filtrando a área homogenea dos dados
ah = [1428,1427,1426,1433,1434,1728]
#filtrando dados do campo para od viagens
campo = ['Leblon','Jardim Atlantico']
# =============================================================================
#criando os Data Frame (tabelas - formato do pandas)
#para domicílio e indivíduos para o bairro Santa Amélia
#consulta área homogenea função pandas query
# =============================================================================
sta_dom = dom.query("ahom in @ah")
sta_ind = ind.query("ahom in @ah")
#renomenado coluna de destino da tabela viagens pra não dar pau
via = via.rename(columns={'desc_campo.1':'desc_campo1'})
# =============================================================================
#criando Data Frame com a variável campor como origem e como destino
#para a OD
# =============================================================================
sta_o = via.query("desc_campo in @campo")
sta_d = via.query("desc_campo1 in @campo")
#criando Data Frame para cidade de BH
bh_dom = dom.where(dom.nm_cidad == 'BELO HORIZONTE')
bh_ind = ind.where(ind.nm_cidad == 'BELO HORIZONTE')

#%%
"""**PARTE 1**
# **DOMICÍLIOS**
---
"""
#%%
#filtrando tempo  de moradia
anos_sta = sta_dom.groupby(['anos_mor']).fator_exp_domic_ah.sum().reset_index().rename(columns={'fator_exp_domic_ah':'STA'})
anos_bh = bh_dom.groupby(['anos_mor']).fator_exp_domic_ah.sum().reset_index().rename(columns={'fator_exp_domic_ah':'BH'})
#cocatenando tabelas
anos = anos_sta.join(anos_bh.set_index('anos_mor'),on='anos_mor')
anos = pd.melt(anos,id_vars=['anos_mor'], value_vars=['BH','STA'],var_name='Local',value_name='Valor')
#criando coluna taxa
anos['Taxa'] = (anos.Valor / anos.groupby('Local').Valor.transform(sum)) * 100
#agrupando por tempo de moradia
fx_mor = np.arange(0,anos['anos_mor'].max()+1,10)
anos['fx_mor'] = pd.cut(anos['anos_mor'],fx_mor)
#agregando as taxas por faixa de tempo de moradia
anos_conf = anos.groupby(['fx_mor','Local']).Taxa.sum()
anos_conf
#%%
#plotando gráfico
fig, ax = plt.subplots(figsize=(8, 5))
sns.barplot(x='fx_mor',y='Taxa',data=anos,hue='Local',hue_order=('STA','BH'),palette='husl',ci=None,estimator=(np.sum))
plt.xlabel('Tempo de Moradia')
plt.ylabel('Taxa em %')
plt.legend(title='Local',loc='upper right',labels=['Santa Amélia','Belo Horizonte'])
#%%
#filtrando tipo de domicílio
domic_sta = sta_dom.groupby(['ds_tp_do']).fator_exp_domic_ah.sum().reset_index().rename(columns={'fator_exp_domic_ah':'STA'})
domic_bh = bh_dom.groupby(['ds_tp_do']).fator_exp_domic_ah.sum().reset_index().rename(columns={'fator_exp_domic_ah':'BH'})
#cocatenando tabelas
domic = domic_sta.join(domic_bh.set_index('ds_tp_do'),on='ds_tp_do')
domic = pd.melt(domic,id_vars=['ds_tp_do'], value_vars=['BH','STA'],var_name='Local',value_name='Valor')
#criando coluna taxa
domic['Taxa'] = (domic.Valor / domic.groupby(['Local']).Valor.transform(sum)) * 100
domic
#%%
#plotando o gráfico
#tipo domicílio
fig, ax = plt.subplots(figsize=(30, 20))
sns.barplot(x='Taxa',y='ds_tp_do',data=domic,hue='Local',hue_order=('STA','BH'),palette='husl',ci=None,estimator=np.sum)
plt.xlabel('Taxa em %')
plt.ylabel('')
plt.legend(title='Local',labels=['Santa Amélia','Belo Horizonte'])
plt.show()
#%%
#filtrando tipo de veículo
#filtrando automóveis
auto_sta = sta_dom.groupby(['qtd_auto']).fator_exp_domic_ah.sum().reset_index().rename(columns={'fator_exp_domic_ah':'STA'})
auto_bh = bh_dom.groupby(['qtd_auto']).fator_exp_domic_ah.sum().reset_index().rename(columns={'fator_exp_domic_ah':'BH'})
#join das tabelas de automovel BH e STA (união)
auto = auto_sta.join(auto_bh.set_index('qtd_auto'),on='qtd_auto')
auto = auto.rename(columns={'qtd_auto':'qtd'})
#criando coluna de categoria
auto['cat'] = 'auto'
auto
#filtrando moto
moto_sta = sta_dom.groupby(['qtd_moto']).fator_exp_domic_ah.sum().reset_index().rename(columns={'fator_exp_domic_ah':'STA'})
moto_bh = bh_dom.groupby(['qtd_moto']).fator_exp_domic_ah.sum().reset_index().rename(columns={'fator_exp_domic_ah':'BH'})
#join das tabelas de moto BH e STA (união)
moto = moto_sta.join(moto_bh.set_index('qtd_moto'),on='qtd_moto')
moto = moto.rename(columns={'qtd_moto':'qtd'})
#criando coluna categoria
moto['cat'] = 'moto'
moto
#cocatenando tabelas de moto de automovel
veic = pd.concat([auto,moto], axis=0)
veic = pd.melt(veic,id_vars=['qtd','cat'],value_name='Valor',var_name='Local')
#criando coluna taxa
veic['Taxa'] = (veic.Valor / veic.groupby(['Local','cat']).Valor.transform(sum))* 100
veic['qtd'] = veic.qtd.astype('int')
veic
#%%
#plotando gráfico
r = sns.FacetGrid(veic, row='cat',row_order=('auto','moto'),col='Local', col_order=('STA','BH'),hue='Local',hue_order=('STA','BH'),palette='husl',height=4,aspect=3, sharex=False)
r.map(sns.barplot,'qtd', 'Taxa', dodge=False,ci=None)
r.add_legend(title='Local',loc='upper right',labels=['Santa Amélia','Belo Horizonte'])
r.set_ylabels('Taxa em %')
r.set_xlabels('Quantidade por Domicílio')
r.axes[0,0].set_title('Automóveis')
r.axes[0,1].set_title('Automóveis')
r.axes[1,0].set_title('Moto')
r.axes[1,1].set_title('Moto')
plt.show()
#%%
"""**PARTE 2**
# **INDIVÍDUOS**
---
"""

#%%
renda = pd.DataFrame()
escol = pd.DataFrame()
regime = pd.DataFrame()
#criando dataframes vazios
#%%
#analisando renda
renda_sta = sta_ind.groupby(['ds_renda','ds_sexo','tp_renda']).fator_exp_pop_ah.sum().reset_index().rename(columns={'fator_exp_pop_ah':'Valor','ds_sexo':'Sexo'})
renda_bh = bh_ind.groupby(['ds_renda','ds_sexo','tp_renda']).fator_exp_pop_ah.sum().reset_index().rename(columns={'fator_exp_pop_ah':'Valor','ds_sexo':'Sexo'})
#criando coluna com Local
renda_sta['Local'] = 'STA'
renda_bh['Local'] = 'BH'
#cocatenando tabelas
renda = pd.concat([renda_sta,renda_bh],axis=0).reset_index()
#criando coluna de taxa
renda['Taxa'] = (renda.Valor / renda.groupby('Local').Valor.transform(sum))*100
renda['Renda'] = renda.ds_renda.str.split("-",n=1,expand=True)[0]
#transformando masculino em negativo para fazer pirâmide
renda['Taxa'] = [-x if Sexo == 'Masculino' else x for Sexo, x in zip(renda['Sexo'],renda['Taxa'])]
#organizando a tabela pelo código de tipo de renda
renda = renda.sort_values(by='tp_renda')
renda
#%%
#analisando escolaridade
escol_sta = sta_ind.groupby(['ds_grau','ds_sexo','tp_grau']).fator_exp_pop_ah.sum().reset_index().rename(columns={'fator_exp_pop_ah':'Valor','ds_sexo':'Sexo','ds_grau':'Escolaridade'})
escol_bh = bh_ind.groupby(['ds_grau','ds_sexo','tp_grau']).fator_exp_pop_ah.sum().reset_index().rename(columns={'fator_exp_pop_ah':'Valor','ds_sexo':'Sexo','ds_grau':'Escolaridade'})
#criando coluna com Local
escol_sta['Local'] = 'STA'
escol_bh['Local'] = 'BH'
#cocatenando tabelas
escol = pd.concat([escol_sta,escol_bh],axis=0)
#criando coluna taxa
escol['Taxa'] = (escol.Valor / escol.groupby('Local').Valor.transform(sum))*100
#transformando masculino em negativo para fazer pirâmide
escol['Taxa'] = [-x if Sexo == 'Masculino' else x for Sexo, x in zip(escol['Sexo'],escol['Taxa'])]
#organzando a tabela pelo código de tipo de grau de escolaridade
escol = escol.sort_values(by='tp_grau')
escol
#%%
#analisando regime de trabalho
regime_sta = sta_ind.groupby(['ds_regim','ds_sexo','tp_regim']).fator_exp_pop_ah.sum().reset_index().rename(columns={'fator_exp_pop_ah':'Valor','ds_sexo':'Sexo','ds_regim':'Regime'})
regime_bh = bh_ind.groupby(['ds_regim','ds_sexo','tp_regim']).fator_exp_pop_ah.sum().reset_index().rename(columns={'fator_exp_pop_ah':'Valor','ds_sexo':'Sexo','ds_regim':'Regime'})
#criando coluna de Local
regime_sta['Local'] = 'STA'
regime_bh['Local'] = 'BH'
#cocatenando tabelas
regime = pd.concat([regime_sta,regime_bh],axis=0)
#criando coluna taxa
regime['Taxa'] = (regime.Valor / regime.groupby('Local').Valor.transform(sum))*100
#transformando masculino em negativo para fazer pirâmide
regime['Taxa'] = [-x if Sexo == 'Masculino' else x for Sexo, x in zip(regime['Sexo'],regime['Taxa'])]
#organizando a tabela pelo código de tipo de regime
regime = regime.sort_values(by='tp_regim')
regime['Taxa'].sum()
#%%
# =============================================================================
# essa linha de código é para alinhar o gráfico porque o feminino no STA
# não tem renda de mais de 20 SM e fica 'bugado'
# o código foi gerado pelo chat gpt
# =============================================================================

# criando um dataframe com todas as combinações de sexo, renda e local
combinacoes = pd.MultiIndex.from_product([renda['Sexo'].unique(), 
                                           renda['Renda'].unique(), 
                                           renda['Local'].unique()], 
                                          names=['Sexo', 'Renda', 'Local'])
df = renda.set_index(['Sexo', 'Renda', 'Local']).reindex(combinacoes)

# preenchendo os valores faltantes com zero
df.fillna(0, inplace=True)

# redefinindo o índice
df.reset_index(inplace=True)
#%%
#plotando os gráficos
#gráfico renda
r = sns.FacetGrid(df, row="Local",row_order=('STA','BH'),hue='Sexo',hue_order=('Masculino','Feminino'), palette='husl',height=4,aspect=3)
r.map_dataframe(sns.barplot,'Taxa', 'Renda', dodge=False)
r.add_legend()
r.set_xlabels('Taxa em %')
r.set_ylabels('Renda')
r.axes[0,0].set_title('Santa Amélia')
r.axes[1,0].set_title('Belo Horizonte')
#%%
#gráfico escolaridade
r = sns.FacetGrid(escol, row="Local",row_order=('STA','BH'),hue='Sexo',hue_order=('Masculino','Feminino'),palette='husl',height=4,aspect=3)
r.map(sns.barplot,'Taxa', 'Escolaridade', dodge=False)
r.add_legend()
#gráfico --> o dodge = False alinha os eixos
r.set_xlabels('Taxa em %')
r.set_ylabels('Grau de Escolaridade')
r.axes[0,0].set_title('Santa Amélia')
r.axes[1,0].set_title('Belo Horizonte')
#%%
#Gráfico Regime
r = sns.FacetGrid(regime, row="Local", row_order=('STA','BH'),hue='Sexo',hue_order=('Masculino','Feminino'), palette='husl',height=4,aspect=3)
r.map(sns.barplot,'Taxa', 'Regime', dodge=False)
r.add_legend()
r.set_xlabels('Taxa em %')
r.set_ylabels('Regime de Trabalho')
r.axes[0,0].set_title('Santa Amélia')
r.axes[1,0].set_title('Belo Horizonte')

#%%
"""**Parte 3**
# **VIAGENS**
"""
via['tempo_de'] = via['tempo_de'].astype(str)
via['tempo_de'] = pd.to_datetime(via['tempo_de'])
via['tempo_de']
#%%
# =============================================================================
# #filtrando o modo no municipio e no campo que contém o bairro
# #nessa parte não usou ah porque o campo vai ter um menor erro para a od viagens
# =============================================================================
modo_bh = via.query("munic_origem == 'BELO HORIZONTE'").groupby('modos_ag').fator_ex.sum().reset_index().rename(columns={'fator_ex':'BH'})
modo_sta = via.query("desc_campo in @campo").groupby('modos_ag').fator_ex.sum().reset_index().rename(columns={'fator_ex':'STA'})
#join entre tabelas (união)
modo = modo_sta.join(modo_bh.set_index('modos_ag'),on='modos_ag')
#transpondo as colunas para ter coluna valor e coluna local
modo = pd.melt(modo,id_vars='modos_ag',value_vars=['BH','STA'],var_name='Local',value_name='Valor')
#criando a coluna taxa
modo['Taxa'] = (modo.Valor / modo.groupby(['Local']).Valor.transform(sum))*100
#%%
#plotando o gráfico do modo
r = sns.FacetGrid(modo, col='Local',col_order=('STA','BH'), hue='Local',hue_order=('STA','BH'),palette='husl',height=4,aspect=1.5)
r.map(sns.barplot,'Taxa', 'modos_ag', dodge=False, ci=None)
r.add_legend(title='Local',loc='upper right',labels=['Santa Amélia','Belo Horizonte'])
r.set_ylabels('Modo de Tranposrte')
r.set_xlabels('Taxa em %')
r.axes[0,0].set_title('Santa Amélia')
r.axes[0,1].set_title('Belo Horizonte')
#não usei esse gráfico no relatório
#%%
#agrupando por sexo e modo
sexo_bh = via.query("munic_origem == 'BELO HORIZONTE'").groupby(['modos_ag','sexo']).fator_ex.sum().reset_index().rename(columns={'fator_ex':'Valor'})
sexo_sta = via.query("desc_campo in @campo").groupby(['modos_ag','sexo']).fator_ex.sum().reset_index().rename(columns={'fator_ex':'Valor'})
#criando coluna com Local
sexo_sta['Local'] = 'STA'
sexo_bh['Local'] = 'BH'
sexo = pd.concat([sexo_sta,sexo_bh],axis=0,ignore_index='index')
#criando coluna taxa#criando coluna taxa
sexo['Taxa'] = (sexo.Valor / sexo.groupby('Local').Valor.transform(sum))*100
#transformando masculino em negativo para fazer pirâmide
sexo['Taxa'] = [-x if sexo == 'Masculino' else x for sexo, x in zip(sexo['sexo'],sexo['Taxa'])]
#%%
#Gráfico Sexo por Modo
r = sns.FacetGrid(sexo, row="Local", row_order=('STA','BH'),hue='sexo',hue_order=('Masculino','Feminino'), palette='husl',height=4,aspect=3,sharey=False)
r.map(sns.barplot,'Taxa', 'modos_ag', dodge=False, order=['Não motorizado','individual','coletivo','Outros'])
r.add_legend()
r.set_xlabels('Taxa em %')
r.set_ylabels('Modo de Transporte')
r.axes[0,0].set_title('Santa Amélia')
r.axes[1,0].set_title('Belo Horizonte')
#%%
# =============================================================================
# #analisando o tempo de viagem de cada modo
# #não tem como fazer gráfico, tentei tabela e achei horrível
# #exportar csv e formatar no relatório no word
# =============================================================================
modo_bh = via.query("munic_origem == 'BELO HORIZONTE'").groupby('modos_ag').tempo_de.mean().reset_index().rename(columns={'tempo_de':'BH'})
modo_sta = via.query("desc_campo in @campo").groupby('modos_ag').tempo_de.mean().reset_index().rename(columns={'tempo_de':'STA'})
modo = modo_sta.join(modo_bh.set_index('modos_ag'),on='modos_ag')
modo = pd.melt(modo,id_vars='modos_ag',value_vars=['BH','STA'],var_name='Local',value_name='Tempo Médio').rename(columns={'modos_ag':'Modo'})
modo['Tempo Médio'] = modo['Tempo Médio'].dt.strftime('%H:%M:%S')
modo['Local'] = modo['Local'].replace('BH', 'Belo Horizonte')
modo['Local'] = modo['Local'].replace('STA', 'Santa Amélia')
modo.to_csv(ROOT+'/tempo_medio.csv',sep=';',index=False)
#%%
#plot da tabela

#modo['Taxa'] = (modo.Valor / modo.groupby(['Local']).Valor.transform(sum))*100
fig, ax = plt.subplots()
plt.rcParams['font.family'] = 'Times New Roman'
plt.rcParams['font.size'] = 10

# hide axes
fig.patch.set_visible(False)
ax.axis('off')
ax.axis('tight')
ax.table(cellText=modo.values,
          colLabels=modo.columns,
          cellLoc='center',
          loc= 'center')

fig.tight_layout()
plt.show()
#%%
#não lembro o que eu tava tentando fazer aqui
tempo = pd.to_datetime(modo['Valor'])
tempo.dt.time
r = sns.FacetGrid(modo, col='Local',col_order=('STA','BH'), hue='Local',hue_order=('STA','BH'),palette='husl',height=4,aspect=1.5)
r.map(sns.barplot,tempo.dt.time, 'modos_ag', dodge=False, ci=None)
r.add_legend(title='Local',loc='upper right',labels=['Santa Amélia','Belo Horizonte'])
r.set_ylabels('Modo de Tranposrte')
r.set_xlabels('Taxa em %')
r.axes[0,0].set_title('Santa Amélia')
r.axes[0,1].set_title('Belo Horizonte')

sta_o.columns
#%%
#gerando a matriz od fazendo uma tabela dinâmica
matriz_od= pd.pivot_table(sta_o,index='desc_campo',columns='desc_campo1',values='fator_ex', aggfunc='sum',margins = True, margins_name='Total')
#matriz_do= pd.pivot_table(sta_o,index='desc_campo1',columns='desc_campo',values='fator_ex', aggfunc='sum')
#matriz_od.to_excel(ROOT+'/matriz_od.xlsx')
#%%
#matriz_od transposta para mapo choloropetico
matriz_od_reverse = pd.pivot_table(sta_o,index='desc_campo1',columns='desc_campo',values='fator_ex',aggfunc='sum')
#trocando valores nan
matriz_od_reverse['Jardim Atlantico'][np.isnan(matriz_od_reverse['Jardim Atlantico'])] = 0
matriz_od_reverse['Leblon'][np.isnan(matriz_od_reverse['Leblon'])] = 0
#calcular total e taxa
matriz_od_reverse['Total'] = matriz_od_reverse['Jardim Atlantico'] + matriz_od_reverse['Leblon']
matriz_od_reverse['Taxa'] = (matriz_od_reverse.Total / matriz_od_reverse.Total.sum())*100
#exportar
#matriz_od_reverse.to_excel(ROOT+'/matriz_od_mapa2.xlsx')
#%%

sns.barplot(data=matriz_od_reverse,x='Taxa',palette='husl',y='desc_campo1',ci=None)
plt.show()


#%%
# Adiciona um mapa de calor ao mapa
zona = gpd.read_file(ROOT+'/Malha-Digital-de-Campos-–-FJP/FJP_Campo.shp')
#%%
zona.plot()
plt.show()
#%%
#SANTA LUZIA
#agrupando dados de faixa etária
via['range_idade']= pd.cut(via.idade,bins=range(0,112,5),include_lowest=False,right=False)
#filtrando a cidade de santa luzia
via.munic_origem.unique()
via = via.rename(columns={'desc_campo.1':'desc_campo1'})
sta_luzia = ['SANTA LUZIA']
sta_luzia = via.query("munic_origem in @sta_luzia & munic_destino in @sta_luzia")
#producao e atracao de viagens
produc = pd.pivot_table(sta_luzia,index='desc_campo',values='fator_ex',aggfunc='sum')
produc
atrac = pd.pivot_table(sta_luzia,index='desc_campo1',values='fator_ex',aggfunc='sum')
atrac
#%%
#colunas para o loop
colunas = sta_luzia.columns
colunas
col_pro = colunas.drop(['identifi', 'domicili', 'pessoa', 'viagem', 'hora_in', 'hora_fim',
       'tempo_de', 'motivo_o', 'motivo_d', 'ah_orige', 'ah_desti',
       'munic_origem', 'munic_destino', 'campo_or', 'desc_campo','desc_campo1', 'campo_de', 'umm_orig', 'umm_dest', 'eixo_con', 'eixo_co1',
       'faixa_ho', 'modo_pri','fator_ex','idade','range_idade','sexo','escolari'])
col_atr = colunas.drop(['identifi', 'domicili', 'pessoa', 'viagem', 'hora_in', 'hora_fim',
       'tempo_de', 'motivo_d', 'ah_orige', 'ah_desti',
       'munic_origem', 'munic_destino', 'campo_or', 'desc_campo1', 'desc_campo','campo_de', 'umm_orig', 'umm_dest', 'eixo_con', 'eixo_co1',
       'faixa_ho', 'modo_pri','fator_ex','idade','range_idade','sexo','renda','escolari'])
#%%
#producao de viagens loop para todas as colunas
tabela_pro = []
for i in col_pro:
    pro_var = pd.pivot_table(sta_luzia,index='desc_campo',values='fator_ex',aggfunc='sum',
                           columns=i)
    pro_var.reset_index()
    tabela_pro.append(pro_var)
tabela_pro = pd.concat(tabela_pro,axis=1)
tabela_pro = pd.concat([produc,tabela_pro],axis=1)
#%%
#atracao de viagens loop para todas as colunas
tabela_atr = []
for i in col_atr:
    atr_var = pd.pivot_table(sta_luzia,index='desc_campo1',values='fator_ex',aggfunc='sum',
                           columns=i)
    atr_var.reset_index()
    tabela_atr.append(atr_var)
tabela_atr = pd.concat(tabela_atr,axis=1)
tabela_atr = pd.concat([atrac,tabela_atr],axis=1)

#%%
tabela_atr = tabela_atr.fillna(0)
y = tabela_atr['fator_ex'].values.reshape(-1,1)
r2_scores = {}
for j in tabela_atr.columns[1:]:
    x = tabela_atr[j].values.reshape(-1,1)
    # Criar um modelo de regressão linear
    model = LinearRegression()
    
    # Ajustar o modelo aos dados
    model.fit(x, y)
    
    # Prever os valores de y
    y_pred = model.predict(x)
    
    # Calcular o R²
    r2 = r2_score(y, y_pred)
    
    # Salvar o R² para a coluna atual
    r2_scores[j] = r2

# Imprimir os resultados
for coluna, r2 in r2_scores.items():
    print(f"R² para {coluna}: {r2}")

r2_atrac = pd.DataFrame.from_dict(r2_scores,orient='index', columns=['R²'])
r2_atrac.to_excel(ROOT+'/r2_atrac.xlsx',index_label='Variavel')


#%%
#filtrando SANTA LUZIA OD INDIVIDUOS
ind.columns
ind.nm_cidad.unique()
sta_luzia_ind = ['SANTA LUZIA']
sta_luzia_ind = ind.query("nm_cidad in @sta_luzia_ind")
sta_luzia_ind.desc_campo.unique()

produc_ind = pd.pivot_table(sta_luzia_ind,index='desc_campo',values='fator_exp_pop_ah',
                            aggfunc='sum')
produc_ind

colunas = sta_luzia_ind.columns
ind_col = colunas.drop(['id_domic', 'id_pesso', 'nm_cidad', 'ahom', 'cod_camp', 'desc_campo',
       'tp_situa', 'ds_situa', 'tp_sexo', 'ds_sexo', 'idade', 'tp_grau',
       'ds_grau', 'tp_traba', 'ds_traba', 'tp_qual', 'ds_qual', 'tp_estud_não',
       'tp_estu_reg', 'tp_estu2_informal', 'ahom_estudo', 'tp_horar',
       'ds_horar', 'tp_condi', 'ds_consd', 'tp_renda', 'tp_regim',
       'ds_regim', 'tp_vincu', 'ds_vincu', 'ahom_trab', 'ds_ativi', 'ds_ativ1',
       'tp_outra', 'ds_outra', 'ahom_trab2', 'ds_ativ2', 'fator_exp_pop_ah'])
ind_pro = []
for i in ind_col:
    pro_var = pd.pivot_table(sta_luzia_ind,index='desc_campo',
                             values='fator_exp_pop_ah',aggfunc='sum',
                             columns=i)
    pro_var.reset_index()
    ind_pro.append(pro_var)
ind_pro = pd.concat(ind_pro,axis=1)
ind_pro = pd.concat([produc_ind,ind_pro],axis=1)
#filtrando populacao
pop = pd.pivot_table(sta_luzia_ind,index='desc_campo',values='fator_exp_pop_ah',
                     aggfunc='sum')
#%%
#filtrando SANTA LUZIA NA OD DOMICILIOS
dom.nm_cidad.unique()
sta_luzia_dom = ['SANTA LUZIA']
sta_luzia_dom = dom.query("nm_cidad in @sta_luzia_dom")
sta_luzia_dom.ds_campo.unique()
#filtrando total de domicilios
tp_dom = pd.pivot_table(sta_luzia_dom, index='ds_campo',values='fator_exp_domic_ah',
                        aggfunc='sum', columns='ds_tp_do')
tp_dom.columns
dom.columns
#%%
#filtrando trabalho, transporte coletivo e população para atração de viagens
trabalho = ['Trabalho (comércio)', 'Trabalho (indústria)', 'Trabalho (serviço)']
atr_trabalho = tabela_atr.get(trabalho)
atr_trabalho = atr_trabalho.sum(axis=1)
atr_coletivo = tabela_atr.coletivo
atrac_final = pd.concat([atrac,pop,atr_coletivo,atr_trabalho],axis=1)
atrac_final.columns
atrac_final = atrac_final.rename(columns={'fator_ex':'ATRACAO',
                                          'fator_exp_pop_ah':'POPULACAO',
                                          0:'TRABALHO'})
atrac_final = atrac_final.rename(columns=str.upper)
atrac_final
#%%
#filtrando a renda para producao
pro_renda = pd.pivot_table(sta_luzia,index='desc_campo',values='fator_ex',
                           aggfunc='sum',columns='renda')
pro_renda_colunas = pro_renda.columns
pro_renda_colunas = pro_renda.columns.drop(['Mais de 10 até 15 SM  - Acima de R$ 6.220,00 até R$ 9.330,00',
                        'Mais de 20 SM - Acima de R$ 12.440,00',
                        'Mais de 3 até 5 SM  - Acima de R$ 1.866,00 até R$ 3.110,00',
                        'Mais de 5 até 10 SM - Acima de R$ 3.110,00 até R$ 6.220,00',
                        'O entrevistado não quis informar a renda'])
pro_renda = pro_renda.get(pro_renda_colunas)
pro_renda = pro_renda.sum(axis=1)
pro_renda
#%%
#filtrando automoveis
dom_auto = pd.pivot_table(sta_luzia_dom,index='ds_campo',values='fator_exp_domic_ah',
                          aggfunc='sum',columns='qtd_auto')
dom_auto
for i in dom_auto.columns:
    fator = int(i)
    dom_auto[i] = fator * dom_auto[i]
dom_auto = dom_auto.sum(axis=1)
dom_auto
#%%
#producao
produc_final = pd.concat([produc,pop,pro_renda,dom_auto],axis=1).rename(columns={
    'fator_ex':'PRODUCAO','fator_exp_pop_ah':'POPULACAO',0:'RENDA',1:'AUTO'})
produc_final.columns
#%%
#exportando tabelas para jogar no R
atrac_final.to_excel(ROOT+'/variaveis_atracao.xlsx',sheet_name='Modelo')
produc_final.to_excel(ROOT+'/variaveis_producao.xlsx',sheet_name='Modelo')
#%%
tabela_pro = tabela_pro.fillna(0)
y = tabela_pro['fator_ex'].values.reshape(-1,1)
r2_scores = {}
for j in tabela_pro.columns[1:]:
    x = tabela_pro[j].values.reshape(-1,1)
    # Criar um modelo de regressão linear
    model = LinearRegression()
    
    # Ajustar o modelo aos dados
    model.fit(x, y)
    
    # Prever os valores de y
    y_pred = model.predict(x)
    
    # Calcular o R²
    r2 = r2_score(y, y_pred)
    
    # Salvar o R² para a coluna atual
    r2_scores[j] = r2

# Imprimir os resultados
for coluna, r2 in r2_scores.items():
    print(f"R² para {coluna}: {r2}")
    
r2_produc = pd.DataFrame.from_dict(r2_scores,orient='index', columns=['R²'])
r2_produc.to_excel(ROOT+'/r2_produc.xlsx',index_label='Variavel')

y = tabela_pro['fator_ex']
html_results = {}

for k in tabela_pro.columns[1:]:
    # Selecionar a coluna atual como a variável independente (x)
    x = tabela_pro[k]
    # Adicionar uma coluna de 1's para o termo constante
    x = sm.add_constant(x)
    # Realizar a regressão linear usando o statsmodels
    model = sm.OLS(y, x)
    results = model.fit()
    
    # Imprimir os resultados estatísticos
    print(f"Resultados para {k}:")
    print(results.summary())
    print("-------------------------------------")
    # Obter o resumo estatístico como dataframe
    summary_df = pd.read_html(results.summary().tables[1].as_html(), header=0, index_col=0)[0]
    
    # Salvar o dataframe em um arquivo HTML
    html_file = f"resultado_{k}.html"
    summary_df.to_html(html_file)
    
    # Adicionar o caminho do arquivo HTML ao dicionário
    html_results[k] = html_file

# Salvar os caminhos dos arquivos HTML em um arquivo CSV
html_df = pd.DataFrame(html_results.items(), columns=['Variavel', 'HTML_File'])
html_df.to_csv('html_files.csv', index=False)
